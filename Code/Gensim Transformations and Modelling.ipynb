{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pickle as pic\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import nltk, string\n",
    "import pandas as pd\n",
    "from gensim import corpora, models, similarities\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from itertools import compress\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data (BOW Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "all_data = pic.load( open(\"../Data/all_data.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get Text and Index\n",
    "ann_text = all_data['ann_text'].values\n",
    "ref_text = all_data['fragment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define normalizer\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens if item not in stop]\n",
    "\n",
    "def normalize(text):\n",
    "    return stem_tokens(nltk.word_tokenize(\n",
    "            text.lower().translate(None, string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize our annotations and Referent Text\n",
    "ann_text_bow = map(normalize, ann_text)\n",
    "ref_text_bow = map(normalize, ref_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get frequency dictionary\n",
    "frequency = defaultdict(int)\n",
    "for text in ann_text_bow:\n",
    "    for token in text:\n",
    "        frequency[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103882"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dictionary with our annotations (only including words that appear more than once)\n",
    "ann_text_mult = [[token for token in text if frequency[token] > 1] \n",
    "         for text in ann_text_bow]\n",
    "\n",
    "dictionary = corpora.Dictionary(ann_text_mult)\n",
    "dictionary.num_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28029"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print Number of Words in the Dictionary\n",
    "len(dictionary.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create our corpus\n",
    "corpus_bow = [dictionary.doc2bow(text) for text in ann_text_mult]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 2), (3, 1), (4, 1), (5, 2), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 2), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1)], [(1, 1), (11, 3), (13, 1), (19, 2), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 3), (27, 1), (28, 1), (29, 1), (30, 2), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 2), (39, 1), (40, 2), (41, 1), (42, 1), (43, 1), (44, 1)], [(11, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1)], [(11, 2), (50, 1), (51, 2), (52, 3), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 2), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 2), (71, 1), (72, 1), (73, 3), (74, 1), (75, 1), (76, 1), (77, 2), (78, 1)], [(2, 1), (4, 1), (10, 1), (11, 1), (13, 1), (20, 1), (71, 1), (79, 1), (80, 1), (81, 2), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 3), (96, 2), (97, 4), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 2), (111, 1), (112, 1), (113, 2)]]\n",
      "103882 98928\n"
     ]
    }
   ],
   "source": [
    "# Print first five sparse vectors in the corpus\n",
    "print corpus_bow[:5]\n",
    "print len(corpus_bow), len(ann_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artist Specific Corpus\n",
    "In order to limit similarity comparisons for our specified query, we need to create a dictionary of artist specific corpuses that we can compare over to subset our search space in order to make it more manageable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create dictionary for storing artist corpuses ad their associated id\n",
    "artist_corpus_dict = {}\n",
    "\n",
    "# Fill dictionary with artist specific corpuses\n",
    "artist_ids = set(all_data['artist_id'])\n",
    "for artist in artist_ids:\n",
    "    id_mask = list(all_data['artist_id'] == artist)\n",
    "    artist_text = compress(ann_text_mult, id_mask)\n",
    "    artist_corpus = [dictionary.doc2bow(text) for text in artist_text]\n",
    "    artist_corpus_dict[artist] = artist_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(artist_corpus_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF and Similarity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tf-Idf our corpus\n",
    "tfidf = models.TfidfModel(corpus_bow)\n",
    "corpus_tfidf = tfidf[corpus_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create indices for querying separated by artist_id\n",
    "artist_index_dict = {}\n",
    "for key, value in artist_corpus_dict.iteritems():\n",
    "    artist_index_dict[key] = similarities.MatrixSimilarity(tfidf[value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 68485,  36527,  17286,  28695,  36167, 100640,  70762,  36919,\n",
       "        15968,  50658,  11274,  89938,  11646,  19443,  97614,  34232,\n",
       "         9171,  92791,  82036,   3490,  99559,  29158,  84038,  11156,\n",
       "        61454,  89478,   8354, 101341,  14149,  39098,   7566,   6450,\n",
       "        85205,  78451,  58198,  88711,  50481,  90716,  41912,  13948,\n",
       "        86181,  87978, 100315,  25885,  66009,  18327,  25822,  96994,\n",
       "        28622,   1060,  17911,  41290,  98243,  35840,  65687,  16202,\n",
       "        43585,  71530,  95925,  68231,  59010,  19185,  47973,  95058,\n",
       "        98601,  74249,  56745,  84678,  42100,  36829,  68630, 101589,\n",
       "        84759,  31210,  45311,   3810,  19319,  43131,  65031,  19732,\n",
       "        97769,  56216,  55815,   9700,  68683,  42051,  95448,  37871,\n",
       "        19062,  48438,  39828,  82020,  47093,   6165,  90172,  53516,\n",
       "         5112,  13345,  54155,  54054])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly Sample 100 referents to compare\n",
    "ref_indices = np.random.choice(range(all_data.shape[0]), 100, replace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create TDIDF representation of our test query (referent)\n",
    "doc = ref_text_bow[2]\n",
    "index = ann_index[2]\n",
    "doc_bow = dictionary.doc2bow(doc)\n",
    "doc_tfidf = tfidf[doc_bow]\n",
    "\n",
    "# Query our index for closely related documents\n",
    "sims_tfidf = index_tfidf[doc_tfidf]\n",
    "sims_tfidf = sorted(enumerate(sims_tfidf), \n",
    "                    key=lambda item: item[1], reverse=True)\n",
    "sims_tfidf = np.array(sims_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18213,     0])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find position of the \"correct\" annotation in the similarity list\n",
    "correct_position = np.where(sims_tfidf[:, 0] == index)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2091]\n",
      "[19]\n",
      "[8559]\n",
      "[2]\n",
      "[40]\n"
     ]
    }
   ],
   "source": [
    "# Repeat for sample of test queries\n",
    "correct_positions = np.zeros(5)\n",
    "for i in range(5):\n",
    "    doc = ref_text_bow[i]\n",
    "    index = ann_index[i]\n",
    "    doc_bow = dictionary.doc2bow(doc)\n",
    "    doc_tfidf = tfidf[doc_bow]\n",
    "\n",
    "    # Query our index for closely related documents\n",
    "    sims_tfidf = index_tfidf[doc_tfidf]\n",
    "    sims_tfidf = sorted(enumerate(sims_tfidf), \n",
    "                        key=lambda item: item[1], reverse=True)\n",
    "    sims_tfidf = np.array(sims_tfidf)\n",
    "    correct_position = np.where(sims_tfidf[:, 0] == index)[0]\n",
    "    print correct_position\n",
    "    correct_positions[i] = correct_position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Analysis and Similarity Calcuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LSI our Tf-idf corpus\n",
    "lsa = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=10)\n",
    "corpus_lsa = lsa[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.11817592009507155), (1, 0.043670656922342309), (2, -0.14992542065700362), (3, -0.023131955586047574), (4, 0.0082964461991998188), (5, -0.0036412197581230563), (6, 0.0052674913880049476), (7, 0.025678545319327541), (8, -0.003650315236654838), (9, 0.0050921255380231801)]\n",
      "[(0, 0.041115382283709485), (1, 0.0459444092820957), (2, -0.01277981635249471), (3, 0.0096576985185838193), (4, -0.0010830974269517796), (5, 0.010359230375508023), (6, 0.0043806227706480547), (7, -0.0031039945281084191), (8, 0.006223285692291719), (9, 0.016255697025536305)]\n",
      "[(0, 0.17895704014220509), (1, -0.00018982998432079748), (2, -0.21609053888732968), (3, -0.047646168829888272), (4, 0.052260601211250153), (5, 0.0017649047671909641), (6, -0.010475616305728644), (7, -0.00059897264687310274), (8, 0.0055253356560165624), (9, 0.0085105921099546487)]\n",
      "[(0, 0.12770153041292825), (1, -0.05397949383748999), (2, -0.19226011773138613), (3, -0.054172426540956664), (4, 0.044355091765307511), (5, -0.026641966038961379), (6, 0.012529233498629128), (7, 0.024090641757074524), (8, 0.0034643536241341847), (9, -0.025682120039912697)]\n",
      "[(0, 0.027777333671402012), (1, -0.013610108095112929), (2, -0.16293224351586577), (3, -0.046308084954383932), (4, 0.020956365148649677), (5, -0.012908461303186227), (6, -0.0067983581380488579), (7, 0.008864232721546109), (8, -0.0035444156111765282), (9, -0.012787742890055758)]\n"
     ]
    }
   ],
   "source": [
    "# Print first ten documents in our LSI corpus\n",
    "for doc in corpus_lsa[:5]:\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create index for querying\n",
    "index_lsa = similarities.MatrixSimilarity(corpus_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create LSA representation of our test query (referent)\n",
    "doc = ref_text_bow[2]\n",
    "index = ann_index[2]\n",
    "doc_bow = dictionary.doc2bow(doc)\n",
    "doc_tfidf = tfidf[doc_bow]\n",
    "doc_lsa = lsa[doc_tfidf]\n",
    "\n",
    "# Query our index for closely related documents\n",
    "sims_lsa = index_lsa[doc_lsa]\n",
    "sims_lsa = sorted(enumerate(sims_lsa), \n",
    "                    key=lambda item: item[1], reverse=True)\n",
    "sims_lsa = np.array(sims_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63523])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find position of the \"correct\" annotation in the similarity list\n",
    "correct_position = np.where(sims_lsa[:, 0] == index)[0]\n",
    "correct_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22915]\n",
      "[7296]\n",
      "[63523]\n",
      "[53994]\n",
      "[98836]\n"
     ]
    }
   ],
   "source": [
    "# Repeat for sample of test queries\n",
    "correct_positions = np.zeros(5)\n",
    "for i in range(5):\n",
    "    doc = ref_text_bow[i]\n",
    "    index = ann_index[i]\n",
    "    doc_bow = dictionary.doc2bow(doc)\n",
    "    doc_tfidf = tfidf[doc_bow]\n",
    "    doc_lsa = lsa[doc_tfidf]\n",
    "\n",
    "    # Query our index for closely related documents\n",
    "    sims_lsa = index_lsa[doc_lsa]\n",
    "    sims_lsa = sorted(enumerate(sims_lsa), \n",
    "                        key=lambda item: item[1], reverse=True)\n",
    "    sims_lsa = np.array(sims_lsa)\n",
    "    correct_position = np.where(sims_lsa[:, 0] == index)[0]\n",
    "    print correct_position\n",
    "    correct_positions[i] = correct_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find position of the \"correct\" annotation in the similarity list\n",
    "correct_position = np.where(sims_lsa[:, 0] == index)[0]\n",
    "correct_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Repeat for sample of test queries\n",
    "correct_positions = np.zeros(5)\n",
    "for i in range(5):\n",
    "    doc = ref_text_bow[i]\n",
    "    index = ann_index[i]\n",
    "    doc_bow = dictionary.doc2bow(doc)\n",
    "    doc_tfidf = tfidf[doc_bow]\n",
    "    doc_lsa = lsa[doc_tfidf]\n",
    "\n",
    "    # Query our index for closely related documents\n",
    "    sims_lsa = index_lsa[doc_lsa]\n",
    "    sims_lsa = sorted(enumerate(sims_lsa), \n",
    "                        key=lambda item: item[1], reverse=True)\n",
    "    sims_lsa = np.array(sims_lsa)\n",
    "    correct_position = np.where(sims_lsa[:, 0] == index)[0]\n",
    "    print correct_position\n",
    "    correct_positions[i] = correct_position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation and Similarity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LDA our BOW corpus\n",
    "lda = models.LdaModel(corpus, id2word=dictionary, num_topics=5)\n",
    "corpus_lda = lda[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.13106263717234684), (2, 0.70330932327740769), (4, 0.15845293007370048)]\n",
      "[(0, 0.010815749492938528), (1, 0.12333716806465662), (2, 0.78145765402605971), (3, 0.073827878405082495), (4, 0.0105615500112626)]\n",
      "[(2, 0.36012623594661347), (4, 0.61327365359313557)]\n",
      "[(0, 0.046939960071494792), (2, 0.14330507832413031), (4, 0.79908502909962764)]\n",
      "[(0, 0.67258756719662194), (1, 0.029010811905071092), (2, 0.24084909912011762), (3, 0.028814185610665444), (4, 0.028738336167523849)]\n"
     ]
    }
   ],
   "source": [
    "# Print first ten documents in our LDA corpus\n",
    "for i in corpus_lda[:5]:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create index for querying\n",
    "index_lda = similarities.MatrixSimilarity(corpus_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create LDA representation of our test query (referent)\n",
    "doc = ref_text_bow[2]\n",
    "index = ann_index[2]\n",
    "doc_bow = dictionary.doc2bow(doc)\n",
    "doc_lda = lda[doc_bow]\n",
    "\n",
    "# Query our index for closely related documents\n",
    "sims_lda = index_lda[doc_lda]\n",
    "sims_lda = sorted(enumerate(sims_lda), \n",
    "                    key=lambda item: item[1], reverse=True)\n",
    "sims_lda = np.array(sims_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([72390])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find position of the \"correct\" annotation in the similarity list\n",
    "correct_position = np.where(sims_lsa[:, 0] == index)[0]\n",
    "correct_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[82307]\n",
      "[71095]\n",
      "[72390]\n",
      "[83366]\n",
      "[98836]\n"
     ]
    }
   ],
   "source": [
    "# Repeat for sample of test queries\n",
    "correct_positions = np.zeros(5)\n",
    "for i in range(5):\n",
    "    doc = ref_text_bow[i]\n",
    "    index = ann_index[i]\n",
    "    doc_bow = dictionary.doc2bow(doc)\n",
    "    doc_lda = lda[doc_bow]\n",
    "\n",
    "    # Query our index for closely related documents\n",
    "    sims_lda = index_lsa[doc_lda]\n",
    "    sims_lda = sorted(enumerate(sims_lda), \n",
    "                        key=lambda item: item[1], reverse=True)\n",
    "    sims_lda = np.array(sims_lsa)\n",
    "    correct_position = np.where(sims_lda[:, 0] == index)[0]\n",
    "    print correct_position\n",
    "    correct_positions[i] = correct_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Bridge]\n",
      " Whole squad on that real shit\n",
      " Whole squad on that real shit\n",
      " Whole squad on that real shit\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "Reference to Redmans hit Tonights Da Night\n",
      "\n",
      "ACCEPTED COMMENT: https://www.youtube.com/watch?v=G6LVIi7pzZI\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "Lil Yachty- u trippin\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "Em is referring to the same Van Dyke Avenue in Yellow Brick Road from his Encore album.\n",
      "This is also a play on words, knowing how much Eminem loves disrespecting women and talking about lesbians, which is shadowing his urge to want to call the girl hes with a dyke (lesbian).\n",
      "\n",
      "Van Dyke Avenue is a street/road in Detroit crossing 8 Mile Road.\n",
      "Its quite long, too:\n",
      "Van Dyke\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "Ready to Die\n",
      "\n",
      "---\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ref_text[4]\n",
    "for i in sims_lda[:5,0]:\n",
    "    print ann_text[i] + \"\\n\\n---\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Dirichlet Process and Similarity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HDP our BOW corpus\n",
    "hdp = models.HdpModel(corpus, id2word=dictionary)\n",
    "corpus_hdp = hdp[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
