{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pickle as pic\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import nltk, string\n",
    "import pandas as pd\n",
    "from gensim import corpora, models, similarities\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data (BOW Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "songs = pic.load( open(\"./Data/songs.p\", \"rb\"))\n",
    "referents = pic.load( open(\"./Data/referents.p\", \"rb\"))\n",
    "annotations = pic.load( open(\"./Data/annotations.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annotations = annotations.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98992, 6)\n",
      "(98928, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>classification</th>\n",
       "      <th>fragment</th>\n",
       "      <th>is_description</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>annotation_index</th>\n",
       "      <th>ref_id</th>\n",
       "      <th>ann_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4961787</td>\n",
       "      <td>156640</td>\n",
       "      <td>accepted</td>\n",
       "      <td>[Part I: 0 to 100]</td>\n",
       "      <td>False</td>\n",
       "      <td>605899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4961787.0</td>\n",
       "      <td>This song was allegedly supposed to be Diddys ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3274596</td>\n",
       "      <td>156640</td>\n",
       "      <td>accepted</td>\n",
       "      <td>[Produced by Boi-1da, Frank Dukes, Noah \"40\" S...</td>\n",
       "      <td>False</td>\n",
       "      <td>104344</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3274596.0</td>\n",
       "      <td>https://twitter.com/Boi1da/status/473262859418...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3272685</td>\n",
       "      <td>156640</td>\n",
       "      <td>accepted</td>\n",
       "      <td>Maybe I'm searchin' for the problems, askin' w...</td>\n",
       "      <td>False</td>\n",
       "      <td>58812</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3272685.0</td>\n",
       "      <td>Like he says in Think Good, Drake is constantl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3272333</td>\n",
       "      <td>156640</td>\n",
       "      <td>accepted</td>\n",
       "      <td>The other night, Lavish Lee told me that I'm a...</td>\n",
       "      <td>False</td>\n",
       "      <td>658401</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3272333.0</td>\n",
       "      <td>Lavish Lee is the best friend of Melissa Shay ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3272181</td>\n",
       "      <td>156640</td>\n",
       "      <td>accepted</td>\n",
       "      <td>[Bridge]\\n Whole squad on that real shit\\n Who...</td>\n",
       "      <td>False</td>\n",
       "      <td>18490</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3272181.0</td>\n",
       "      <td>Drakes only squads are OVO (and TOPSZN lowkey)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  song_id classification  \\\n",
       "0  4961787   156640       accepted   \n",
       "1  3274596   156640       accepted   \n",
       "2  3272685   156640       accepted   \n",
       "3  3272333   156640       accepted   \n",
       "4  3272181   156640       accepted   \n",
       "\n",
       "                                            fragment is_description  \\\n",
       "0                                 [Part I: 0 to 100]          False   \n",
       "1  [Produced by Boi-1da, Frank Dukes, Noah \"40\" S...          False   \n",
       "2  Maybe I'm searchin' for the problems, askin' w...          False   \n",
       "3  The other night, Lavish Lee told me that I'm a...          False   \n",
       "4  [Bridge]\\n Whole squad on that real shit\\n Who...          False   \n",
       "\n",
       "   annotator_id  annotation_index     ref_id  \\\n",
       "0        605899               0.0  4961787.0   \n",
       "1        104344               1.0  3274596.0   \n",
       "2         58812               2.0  3272685.0   \n",
       "3        658401               3.0  3272333.0   \n",
       "4         18490               4.0  3272181.0   \n",
       "\n",
       "                                            ann_text  \n",
       "0  This song was allegedly supposed to be Diddys ...  \n",
       "1  https://twitter.com/Boi1da/status/473262859418...  \n",
       "2  Like he says in Think Good, Drake is constantl...  \n",
       "3  Lavish Lee is the best friend of Melissa Shay ...  \n",
       "4  Drakes only squads are OVO (and TOPSZN lowkey)...  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each referent, find the corresponding annotation and merge them\n",
    "print referents.shape\n",
    "ann_merge = annotations[['index', 'ref_id', 'ann_text']]\n",
    "ann_merge.rename(columns={'index': 'annotation_index'}, inplace=True)\n",
    "ref_ann = pd.merge(referents, ann_merge, how='left',\n",
    "                   left_on='id', right_on='ref_id')\n",
    "ref_ann.dropna(inplace=True)\n",
    "print ref_ann.shape\n",
    "ref_ann.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get Text and Index\n",
    "ann_text = ref_ann['ann_text'].values\n",
    "ref_text = ref_ann['fragment'].values\n",
    "ann_index = ref_ann['annotation_index'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define normalizer\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens if item not in stop]\n",
    "\n",
    "def normalize(text):\n",
    "    return stem_tokens(nltk.word_tokenize(\n",
    "            text.lower().translate(None, string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize our annotations and Referent Text\n",
    "ann_text_bow = map(normalize, ann_text)\n",
    "ref_text_bow = map(normalize, ref_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get frequency dictionary\n",
    "frequency = defaultdict(int)\n",
    "for text in ann_text_bow:\n",
    "    for token in text:\n",
    "        frequency[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98928"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dictionary with our annotations\n",
    "ann_text_mult = [[token for token in text if frequency[token] > 1] \n",
    "         for text in ann_text_bow]\n",
    "\n",
    "dictionary = corpora.Dictionary(ann_text_mult)\n",
    "dictionary.num_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27552"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print Number of Words in the Dictionary\n",
    "len(dictionary.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create our corpus\n",
    "corpus_bow = [dictionary.doc2bow(text) for text in ann_text_mult]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 2), (1, 5), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 3), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 2), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 1), (36, 1), (37, 1), (38, 3), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1)], [(0, 1), (5, 1), (7, 1), (26, 1), (27, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 2), (55, 1), (56, 1)], [(35, 2), (38, 2), (57, 1), (58, 1), (59, 1), (60, 1), (61, 2), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1)], [(30, 1), (38, 3), (58, 1), (68, 1), (74, 2), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 3), (82, 1), (83, 1), (84, 1), (85, 2), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 2), (94, 1), (95, 2), (96, 1), (97, 1), (98, 1)], [(38, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1)]]\n",
      "98928 98928\n"
     ]
    }
   ],
   "source": [
    "# Print first five sparse vectors in the corpus\n",
    "print corpus_bow[:5]\n",
    "print len(corpus_bow), len(ann_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF and Similarity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tf-Idf our corpus\n",
    "tfidf = models.TfidfModel(corpus_bow)\n",
    "corpus_tfidf = tfidf[corpus_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.29669811169033694), (1, 0.560592588135255), (2, 0.11718476190786585), (3, 0.08586748495348616), (4, 0.09624514336534767), (5, 0.0583116301708491), (6, 0.1270862129940806), (7, 0.2909223590347693), (8, 0.1104633742542093), (9, 0.09077523620896319), (10, 0.08881103476495539), (11, 0.06936932203487713), (12, 0.06798536456860937), (13, 0.08273502417983959), (14, 0.045852794072612675), (15, 0.12570170890726629), (16, 0.18191608105754248), (17, 0.07349411353976541), (18, 0.10009791437248157), (19, 0.08590458222000975), (20, 0.1790282047297587), (21, 0.09647222630900462), (22, 0.16032165232065493), (23, 0.055125131018004765), (24, 0.08579351007563972), (25, 0.0782159470839777), (26, 0.07616467456968423), (27, 0.23207483376624863), (28, 0.10115708108438375), (29, 0.12595046444972957), (30, 0.08794248051961315), (31, 0.11851252982798778), (32, 0.1356255777554609), (33, 0.10759518695973828), (34, 0.1295122849247989), (35, 0.03728700313686689), (36, 0.09072713833023852), (37, 0.11622382751041885), (38, 0.15627485484203552), (39, 0.046671633128962664), (40, 0.07627539660281066), (41, 0.08257890566409895), (42, 0.1523998040946671), (43, 0.10111521712624152), (44, 0.10521216543237938)]\n",
      "[(0, 0.2876349145950476), (5, 0.11306078537901552), (7, 0.282035593074794), (26, 0.1476761651107213), (27, 0.22498567520269402), (45, 0.2930664589575033), (46, 0.2560032152102237), (47, 0.23189712483191124), (48, 0.3307011411824274), (49, 0.14976874157111422), (50, 0.25200757678351704), (51, 0.2600185039972061), (52, 0.11498437827830456), (53, 0.2059660542149477), (54, 0.3114882469541882), (55, 0.141654275915532), (56, 0.3341631586154716)]\n",
      "[(35, 0.18100417171546454), (38, 0.2528709584302794), (57, 0.3845778314211622), (58, 0.1529866247232257), (59, 0.22266590240431544), (60, 0.09870707220547936), (61, 0.3072582909905497), (62, 0.1322896510858765), (63, 0.2757404694326701), (64, 0.24934393679104686), (65, 0.3136136584122852), (66, 0.150933586344095), (67, 0.20622045085193408), (68, 0.10382721524941953), (69, 0.23391795200566742), (70, 0.16363101118455817), (71, 0.25184547107717925), (72, 0.2798770447839591), (73, 0.15767273379321253)]\n",
      "[(30, 0.11948084529333867), (38, 0.21231891168291483), (58, 0.08563512358216914), (68, 0.05811786765779067), (74, 0.16967360525783026), (75, 0.12439853187531363), (76, 0.20705417118305022), (77, 0.08858191254313029), (78, 0.07469028790562761), (79, 0.13458257594957768), (80, 0.11309673412078401), (81, 0.5289668282791041), (82, 0.07006505489150043), (83, 0.09845904157452494), (84, 0.06562504220828907), (85, 0.21563721116179901), (86, 0.2008533476344593), (87, 0.2751182963103754), (88, 0.13267089298968113), (89, 0.25179628425967454), (90, 0.12720945520563123), (91, 0.09125711890414691), (92, 0.16455700951534016), (93, 0.229680563108821), (94, 0.1776692905738488), (95, 0.2214731597230005), (96, 0.1629556869838115), (97, 0.18187100493511388), (98, 0.10783639840466586)]\n",
      "[(38, 0.1625940521751414), (99, 0.44501537603777186), (100, 0.39772900893720425), (101, 0.4717871490004526), (102, 0.5323725858109122), (103, 0.3336651624789212)]\n"
     ]
    }
   ],
   "source": [
    "# Print first five documents in our LSI corpus\n",
    "for doc in corpus_tfidf[:5]:\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create index for querying\n",
    "index_tfidf = similarities.MatrixSimilarity(corpus_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create TDIDF representation of our test query (referent)\n",
    "doc = ref_text_bow[2]\n",
    "index = ann_index[2]\n",
    "doc_bow = dictionary.doc2bow(doc)\n",
    "doc_tfidf = tfidf[doc_bow]\n",
    "\n",
    "# Query our index for closely related documents\n",
    "sims_tfidf = index_tfidf[doc_tfidf]\n",
    "sims_tfidf = sorted(enumerate(sims_tfidf), \n",
    "                    key=lambda item: item[1], reverse=True)\n",
    "sims_tfidf = np.array(sims_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18213,     0])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find position of the \"correct\" annotation in the similarity list\n",
    "correct_position = np.where(sims_tfidf[:, 0] == index)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2091]\n",
      "[19]\n",
      "[8559]\n",
      "[2]\n",
      "[40]\n"
     ]
    }
   ],
   "source": [
    "# Repeat for sample of test queries\n",
    "correct_positions = np.zeros(5)\n",
    "for i in range(5):\n",
    "    doc = ref_text_bow[i]\n",
    "    index = ann_index[i]\n",
    "    doc_bow = dictionary.doc2bow(doc)\n",
    "    doc_tfidf = tfidf[doc_bow]\n",
    "\n",
    "    # Query our index for closely related documents\n",
    "    sims_tfidf = index_tfidf[doc_tfidf]\n",
    "    sims_tfidf = sorted(enumerate(sims_tfidf), \n",
    "                        key=lambda item: item[1], reverse=True)\n",
    "    sims_tfidf = np.array(sims_tfidf)\n",
    "    correct_position = np.where(sims_tfidf[:, 0] == index)[0]\n",
    "    print correct_position\n",
    "    correct_positions[i] = correct_position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Analysis and Similarity Calcuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LSI our Tf-idf corpus\n",
    "lsa = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=10)\n",
    "corpus_lsa = lsa[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.11817592009507155), (1, 0.043670656922342309), (2, -0.14992542065700362), (3, -0.023131955586047574), (4, 0.0082964461991998188), (5, -0.0036412197581230563), (6, 0.0052674913880049476), (7, 0.025678545319327541), (8, -0.003650315236654838), (9, 0.0050921255380231801)]\n",
      "[(0, 0.041115382283709485), (1, 0.0459444092820957), (2, -0.01277981635249471), (3, 0.0096576985185838193), (4, -0.0010830974269517796), (5, 0.010359230375508023), (6, 0.0043806227706480547), (7, -0.0031039945281084191), (8, 0.006223285692291719), (9, 0.016255697025536305)]\n",
      "[(0, 0.17895704014220509), (1, -0.00018982998432079748), (2, -0.21609053888732968), (3, -0.047646168829888272), (4, 0.052260601211250153), (5, 0.0017649047671909641), (6, -0.010475616305728644), (7, -0.00059897264687310274), (8, 0.0055253356560165624), (9, 0.0085105921099546487)]\n",
      "[(0, 0.12770153041292825), (1, -0.05397949383748999), (2, -0.19226011773138613), (3, -0.054172426540956664), (4, 0.044355091765307511), (5, -0.026641966038961379), (6, 0.012529233498629128), (7, 0.024090641757074524), (8, 0.0034643536241341847), (9, -0.025682120039912697)]\n",
      "[(0, 0.027777333671402012), (1, -0.013610108095112929), (2, -0.16293224351586577), (3, -0.046308084954383932), (4, 0.020956365148649677), (5, -0.012908461303186227), (6, -0.0067983581380488579), (7, 0.008864232721546109), (8, -0.0035444156111765282), (9, -0.012787742890055758)]\n"
     ]
    }
   ],
   "source": [
    "# Print first ten documents in our LSI corpus\n",
    "for doc in corpus_lsa[:5]:\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create index for querying\n",
    "index_lsa = similarities.MatrixSimilarity(corpus_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create LSA representation of our test query (referent)\n",
    "doc = ref_text_bow[2]\n",
    "index = ann_index[2]\n",
    "doc_bow = dictionary.doc2bow(doc)\n",
    "doc_tfidf = tfidf[doc_bow]\n",
    "doc_lsa = lsa[doc_tfidf]\n",
    "\n",
    "# Query our index for closely related documents\n",
    "sims_lsa = index_lsa[doc_lsa]\n",
    "sims_lsa = sorted(enumerate(sims_lsa), \n",
    "                    key=lambda item: item[1], reverse=True)\n",
    "sims_lsa = np.array(sims_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63523])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find position of the \"correct\" annotation in the similarity list\n",
    "correct_position = np.where(sims_lsa[:, 0] == index)[0]\n",
    "correct_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22915]\n",
      "[7296]\n",
      "[63523]\n",
      "[53994]\n",
      "[98836]\n"
     ]
    }
   ],
   "source": [
    "# Repeat for sample of test queries\n",
    "correct_positions = np.zeros(5)\n",
    "for i in range(5):\n",
    "    doc = ref_text_bow[i]\n",
    "    index = ann_index[i]\n",
    "    doc_bow = dictionary.doc2bow(doc)\n",
    "    doc_tfidf = tfidf[doc_bow]\n",
    "    doc_lsa = lsa[doc_tfidf]\n",
    "\n",
    "    # Query our index for closely related documents\n",
    "    sims_lsa = index_lsa[doc_lsa]\n",
    "    sims_lsa = sorted(enumerate(sims_lsa), \n",
    "                        key=lambda item: item[1], reverse=True)\n",
    "    sims_lsa = np.array(sims_lsa)\n",
    "    correct_position = np.where(sims_lsa[:, 0] == index)[0]\n",
    "    print correct_position\n",
    "    correct_positions[i] = correct_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find position of the \"correct\" annotation in the similarity list\n",
    "correct_position = np.where(sims_lsa[:, 0] == index)[0]\n",
    "correct_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Repeat for sample of test queries\n",
    "correct_positions = np.zeros(5)\n",
    "for i in range(5):\n",
    "    doc = ref_text_bow[i]\n",
    "    index = ann_index[i]\n",
    "    doc_bow = dictionary.doc2bow(doc)\n",
    "    doc_tfidf = tfidf[doc_bow]\n",
    "    doc_lsa = lsa[doc_tfidf]\n",
    "\n",
    "    # Query our index for closely related documents\n",
    "    sims_lsa = index_lsa[doc_lsa]\n",
    "    sims_lsa = sorted(enumerate(sims_lsa), \n",
    "                        key=lambda item: item[1], reverse=True)\n",
    "    sims_lsa = np.array(sims_lsa)\n",
    "    correct_position = np.where(sims_lsa[:, 0] == index)[0]\n",
    "    print correct_position\n",
    "    correct_positions[i] = correct_position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation and Similarity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LDA our BOW corpus\n",
    "lda = models.LdaModel(corpus, id2word=dictionary, num_topics=5)\n",
    "corpus_lda = lda[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.13106263717234684), (2, 0.70330932327740769), (4, 0.15845293007370048)]\n",
      "[(0, 0.010815749492938528), (1, 0.12333716806465662), (2, 0.78145765402605971), (3, 0.073827878405082495), (4, 0.0105615500112626)]\n",
      "[(2, 0.36012623594661347), (4, 0.61327365359313557)]\n",
      "[(0, 0.046939960071494792), (2, 0.14330507832413031), (4, 0.79908502909962764)]\n",
      "[(0, 0.67258756719662194), (1, 0.029010811905071092), (2, 0.24084909912011762), (3, 0.028814185610665444), (4, 0.028738336167523849)]\n"
     ]
    }
   ],
   "source": [
    "# Print first ten documents in our LDA corpus\n",
    "for i in corpus_lda[:5]:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create index for querying\n",
    "index_lda = similarities.MatrixSimilarity(corpus_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create LDA representation of our test query (referent)\n",
    "doc = ref_text_bow[2]\n",
    "index = ann_index[2]\n",
    "doc_bow = dictionary.doc2bow(doc)\n",
    "doc_lda = lda[doc_bow]\n",
    "\n",
    "# Query our index for closely related documents\n",
    "sims_lda = index_lda[doc_lda]\n",
    "sims_lda = sorted(enumerate(sims_lda), \n",
    "                    key=lambda item: item[1], reverse=True)\n",
    "sims_lda = np.array(sims_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([72390])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find position of the \"correct\" annotation in the similarity list\n",
    "correct_position = np.where(sims_lsa[:, 0] == index)[0]\n",
    "correct_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[82307]\n",
      "[71095]\n",
      "[72390]\n",
      "[83366]\n",
      "[98836]\n"
     ]
    }
   ],
   "source": [
    "# Repeat for sample of test queries\n",
    "correct_positions = np.zeros(5)\n",
    "for i in range(5):\n",
    "    doc = ref_text_bow[i]\n",
    "    index = ann_index[i]\n",
    "    doc_bow = dictionary.doc2bow(doc)\n",
    "    doc_lda = lda[doc_bow]\n",
    "\n",
    "    # Query our index for closely related documents\n",
    "    sims_lda = index_lsa[doc_lda]\n",
    "    sims_lda = sorted(enumerate(sims_lda), \n",
    "                        key=lambda item: item[1], reverse=True)\n",
    "    sims_lda = np.array(sims_lsa)\n",
    "    correct_position = np.where(sims_lda[:, 0] == index)[0]\n",
    "    print correct_position\n",
    "    correct_positions[i] = correct_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Bridge]\n",
      " Whole squad on that real shit\n",
      " Whole squad on that real shit\n",
      " Whole squad on that real shit\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "Reference to Redmans hit Tonights Da Night\n",
      "\n",
      "ACCEPTED COMMENT: https://www.youtube.com/watch?v=G6LVIi7pzZI\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "Lil Yachty- u trippin\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "Em is referring to the same Van Dyke Avenue in Yellow Brick Road from his Encore album.\n",
      "This is also a play on words, knowing how much Eminem loves disrespecting women and talking about lesbians, which is shadowing his urge to want to call the girl hes with a dyke (lesbian).\n",
      "\n",
      "Van Dyke Avenue is a street/road in Detroit crossing 8 Mile Road.\n",
      "Its quite long, too:\n",
      "Van Dyke\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "Ready to Die\n",
      "\n",
      "---\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ref_text[4]\n",
    "for i in sims_lda[:5,0]:\n",
    "    print ann_text[i] + \"\\n\\n---\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Dirichlet Process and Similarity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HDP our BOW corpus\n",
    "hdp = models.HdpModel(corpus, id2word=dictionary)\n",
    "corpus_hdp = hdp[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
